{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(samplewise_center=True)\n",
    "valid_datagen = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "train_dir = 'deepfake_database/train_test'\n",
    "valid_dir = 'deepfake_database/validation'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # This is the target directory\n",
    "    target_size=(256, 256),  # All images will be resized to 256x256\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    "    )  # Since you use binary_crossentropy loss, you need binary labels\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,  # This is the target directory\n",
    "    target_size=(256, 256),  # All images will be resized to 256x256\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    # shuffle=False\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the classes indices\n",
    "print(train_generator.class_indices)\n",
    "print(valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MesoInception4()\n",
    "model.load('weights/M4I_DF_retrained_galma_best.h5')\n",
    "\n",
    "# model = Meso4()\n",
    "# model.load('weights/Meso4_DF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10, verbose=1, mode='max', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Automatically set steps based on dataset size\n",
    "      epochs=15, \n",
    "      validation_data=valid_generator,\n",
    "      validation_steps=valid_generator.samples // valid_generator.batch_size,  # Automatically set steps based on dataset size\n",
    "      verbose=1,\n",
    "      callbacks=[early_stopping]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "train_loss, train_accuracy = model.model.evaluate(train_generator)\n",
    "print(\"Training Loss:\", train_loss)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluate on validation data\n",
    "valid_loss, valid_accuracy = model.model.evaluate(valid_generator)\n",
    "print(\"Validation Loss:\", valid_loss)\n",
    "print(\"Validation Accuracy:\", valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['Training', 'Validation'], [train_accuracy, valid_accuracy], color=['orange', 'pink'])\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faces Mean Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'batch_normalization_7'  # Name of the last conv layer \n",
    "intermediate_layer_model = Model(inputs=model.model.input,\n",
    "                                 outputs=model.model.get_layer(layer_name).output)\n",
    "\n",
    "# datagen = ImageDataGenerator(rescale=1./255)\n",
    "datagen = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "# Create a generator for the images\n",
    "generator = datagen.flow_from_directory(\n",
    "    # directory='deepfake_database/train_test',  # replace with your directory path\n",
    "    # directory = 'deepfake_database_v2/train_test',\n",
    "    directory='test_images_v2',\n",
    "    # directory = 'deepfake_database_v2/validation',\n",
    "    target_size=(256, 256),  # target size as per your model's input\n",
    "    batch_size=64,  # can be set to any size that fits your memory\n",
    "    class_mode=None,  # since we don't need the labels for activation extraction\n",
    "    shuffle=False  # you don't need to shuffle for this purpose\n",
    ")\n",
    "\n",
    "activations = intermediate_layer_model.predict(generator, steps=len(generator))\n",
    "\n",
    "# Initialize an array to accumulate the activations\n",
    "accumulated_activations = []\n",
    "\n",
    "# Process the images and collect the activations\n",
    "for i in range(len(generator)):  \n",
    "    images = generator.next()\n",
    "    activations = intermediate_layer_model.predict(images)\n",
    "    accumulated_activations.append(activations)\n",
    "\n",
    "# Now concatenate the list of activations into one array\n",
    "all_activations = np.concatenate(accumulated_activations, axis=0)\n",
    "\n",
    "# Calculate the mean across all batches for each filter\n",
    "mean_activations = np.mean(all_activations, axis=0)\n",
    "\n",
    "# mean_activations is now an array of the same shape as the activation outputs of the layer,\n",
    "# but each activation is the mean activation for that filter across all images\n",
    "# Number of filters in the convolutional layer\n",
    "num_filters = mean_activations.shape[-1]\n",
    "\n",
    "# Set the number of filters you want to display\n",
    "num_filters_to_display = min(num_filters, 64)  # for example, to display up to 64 filters\n",
    "\n",
    "# Set the grid dimensions for the subplots\n",
    "grid_dim = int(np.ceil(np.sqrt(num_filters_to_display)))\n",
    "\n",
    "# Create a figure to hold the subplots\n",
    "fig, axes = plt.subplots(grid_dim, grid_dim, figsize=(20, 20))\n",
    "\n",
    "# Iterate over all the filters\n",
    "for i in range(num_filters_to_display):\n",
    "    # Get the mean activation for the i-th filter\n",
    "    filter_activation = mean_activations[:, :, i]\n",
    "    \n",
    "    # Find the row and column we're on\n",
    "    row = i // grid_dim\n",
    "    column = i % grid_dim\n",
    "    \n",
    "    ax = axes[row, column]\n",
    "    \n",
    "    # Display the mean activation for this filter\n",
    "    ax.imshow(filter_activation, cmap='viridis')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "# If the number of filters is not a perfect square, turn off the axes for empty subplots\n",
    "for i in range(num_filters_to_display, grid_dim * grid_dim):\n",
    "    axes.flatten()[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chelo\\Desktop\\Intro to Machine Learning\\Final Project - ML\\MesoNet\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('weights/M4I_DF_retrained_galma_best.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
